{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.7 64-bit",
   "display_name": "Python 3.7.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "04635d289a519a1410467dd0afb0db42f9184808881ca68b2eb5a687a20a5a94"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# word2vec\n",
    "It's a shallow, two-layer neural network that accepts a text corpus as an input, and it returns a set of vectors (also known as embeddings); each vector is a numeric representation of a given word"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "wiki_embeddings = api.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([-0.32307 , -0.87616 ,  0.21977 ,  0.25268 ,  0.22976 ,  0.7388  ,\n       -0.37954 , -0.35307 , -0.84369 , -1.1113  , -0.30266 ,  0.33178 ,\n       -0.25113 ,  0.30448 , -0.077491, -0.89815 ,  0.092496, -1.1407  ,\n       -0.58324 ,  0.66869 , -0.23122 , -0.95855 ,  0.28262 , -0.078848,\n        0.75315 ,  0.26584 ,  0.3422  , -0.33949 ,  0.95608 ,  0.065641,\n        0.45747 ,  0.39835 ,  0.57965 ,  0.39267 , -0.21851 ,  0.58795 ,\n       -0.55999 ,  0.63368 , -0.043983, -0.68731 , -0.37841 ,  0.38026 ,\n        0.61641 , -0.88269 , -0.12346 , -0.37928 , -0.38318 ,  0.23868 ,\n        0.6685  , -0.43321 , -0.11065 ,  0.081723,  1.1569  ,  0.78958 ,\n       -0.21223 , -2.3211  , -0.67806 ,  0.44561 ,  0.65707 ,  0.1045  ,\n        0.46217 ,  0.19912 ,  0.25802 ,  0.057194,  0.53443 , -0.43133 ,\n       -0.34311 ,  0.59789 , -0.58417 ,  0.068995,  0.23944 , -0.85181 ,\n        0.30379 , -0.34177 , -0.25746 , -0.031101, -0.16285 ,  0.45169 ,\n       -0.91627 ,  0.64521 ,  0.73281 , -0.22752 ,  0.30226 ,  0.044801,\n       -0.83741 ,  0.55006 , -0.52506 , -1.7357  ,  0.4751  , -0.70487 ,\n        0.056939, -0.7132  ,  0.089623,  0.41394 , -1.3363  , -0.61915 ,\n       -0.33089 , -0.52881 ,  0.16483 , -0.98878 ], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "wiki_embeddings['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(&#39;prince&#39;, 0.7682329416275024),\n (&#39;queen&#39;, 0.7507690191268921),\n (&#39;son&#39;, 0.7020887136459351),\n (&#39;brother&#39;, 0.6985775232315063),\n (&#39;monarch&#39;, 0.6977890729904175),\n (&#39;throne&#39;, 0.6919990181922913),\n (&#39;kingdom&#39;, 0.6811410188674927),\n (&#39;father&#39;, 0.680202841758728),\n (&#39;emperor&#39;, 0.6712858080863953),\n (&#39;ii&#39;, 0.6676074266433716)]"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "wiki_embeddings.most_similar('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  label  \\\n0   ham   \n1   ham   \n2  spam   \n3   ham   \n4   ham   \n\n                                                                                                  text  \n0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...  \n1                                                                        Ok lar... Joking wif u oni...  \n2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n3                                                    U dun say so early hor... U c already then say...  \n4                                        Nah I don&#39;t think he goes to usf, he lives around here though  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives around here though</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "messages = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "messages = messages.drop(labels=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)\n",
    "messages.columns = ['label', 'text']\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  label  \\\n0   ham   \n1   ham   \n2  spam   \n3   ham   \n4   ham   \n\n                                                                                                  text  \\\n0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n1                                                                        Ok lar... Joking wif u oni...   \n2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n3                                                    U dun say so early hor... U c already then say...   \n4                                        Nah I don&#39;t think he goes to usf, he lives around here though   \n\n                                                                                            clean_text  \n0  [go, until, jurong, point, crazy, available, only, in, bugis, great, world, la, buffet, cine, th...  \n1                                                                          [ok, lar, joking, wif, oni]  \n2  [free, entry, in, wkly, comp, to, win, fa, cup, final, tkts, st, may, text, fa, to, to, receive,...  \n3                                                       [dun, say, so, early, hor, already, then, say]  \n4                                [nah, don, think, he, goes, to, usf, he, lives, around, here, though]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n      <th>clean_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n      <td>[go, until, jurong, point, crazy, available, only, in, bugis, great, world, la, buffet, cine, th...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n      <td>[ok, lar, joking, wif, oni]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n      <td>[free, entry, in, wkly, comp, to, win, fa, cup, final, tkts, st, may, text, fa, to, to, receive,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n      <td>[dun, say, so, early, hor, already, then, say]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives around here though</td>\n      <td>[nah, don, think, he, goes, to, usf, he, lives, around, here, though]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "messages['clean_text'] = messages['text'].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(messages['clean_text'], messages['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.Word2Vec(X_train, size=100, window=5, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(&#39;watching&#39;, 0.9976290464401245),\n (&#39;didn&#39;, 0.9974445700645447),\n (&#39;quite&#39;, 0.9974321126937866),\n (&#39;put&#39;, 0.9974194765090942),\n (&#39;lor&#39;, 0.9974073767662048),\n (&#39;ok&#39;, 0.9974033236503601),\n (&#39;dad&#39;, 0.9974023699760437),\n (&#39;probably&#39;, 0.9973987340927124),\n (&#39;Ã¬_&#39;, 0.9973981380462646),\n (&#39;ever&#39;, 0.997397780418396)]"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[&#39;to&#39;, &#39;then&#39;, &#39;week&#39;, &#39;im&#39;, &#39;wait&#39;, &#39;live&#39;, &#39;house&#39;, &#39;ill&#39;, &#39;plz&#39;, &#39;working&#39;]\n"
    }
   ],
   "source": [
    "print(w2v_model.wv.index2word[0:500:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every word in message list of words X_test is returned as the vector learned only if such word is has been learned\n",
    "w2v_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in w2v_model.wv.index2word]) for ls in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "14 12\n25 21\n12 12\n23 22\n9 9\n"
    }
   ],
   "source": [
    "for i, v in enumerate(w2v_vect):\n",
    "    if(i<5):\n",
    "        print(len(X_test.iloc[i]), len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w2v_vect_avg = []\n",
    "for vect in w2v_vect:\n",
    "    if(len(vect)!=0):\n",
    "        w2v_vect_avg.append(vect.mean(axis=0)) # Don't understand why the length will became 100!!!\n",
    "    else:\n",
    "        w2v_vect_avg.append(np.zeros(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "14 100\n25 100\n12 100\n23 100\n9 100\n"
    }
   ],
   "source": [
    "for i, v in enumerate(w2v_vect_avg):\n",
    "    if(i<5):\n",
    "        print(len(X_test.iloc[i]), len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}